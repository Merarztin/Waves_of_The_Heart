{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4726ccf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/sentissi/code/Merarztin/Waves_of_The_Heart\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "78880705",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Path of the folder containing CSV files\n",
    "folder_path = '/Users/sentissi/code/Merarztin/Waves_of_The_Heart'\n",
    "\n",
    "# Create a list of the filenames of the CSV files to merge\n",
    "file_list = [\n",
    "    'final_dataframe_from_a.csv',\n",
    "    'final_dataframe_from_b.csv',\n",
    "    'final_dataframe_from_c.csv',\n",
    "    'final_dataframe_from_d.csv',\n",
    "    'final_dataframe_from_e.csv',\n",
    "    'final_dataframe_from_f.csv'\n",
    "    \n",
    "]\n",
    "\n",
    "# Create an empty list to store the dataframes\n",
    "df_list = []\n",
    "\n",
    "# Loop through each CSV file in the file_list, read it into a dataframe, and append to df_list\n",
    "for file in file_list:\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    df_list.append(df)\n",
    "\n",
    "# Concatenate all the dataframes in df_list into a single dataframe\n",
    "audio_data = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# Write the merged dataframe to a CSV file\n",
    "audio_data.to_csv('/Users/sentissi/code/Merarztin/Waves_of_The_Heart/merged_file.csv', index=False)\n",
    "audio_data = audio_data.drop('Unnamed: 0', axis=1)\n",
    "audio_data = audio_data.drop('wav_file', axis=1)\n",
    "\n",
    "\n",
    "# uncomment to save audio_data\n",
    "#audio_data.to_csv('audio_data.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "fb2ad2f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Decomp0_Duration</th>\n",
       "      <th>Decomp0_Energy</th>\n",
       "      <th>Decomp0_Peak Amplitude</th>\n",
       "      <th>Decomp0_Mean Amplitude</th>\n",
       "      <th>Decomp0_Std Amplitude</th>\n",
       "      <th>Decomp0_Skew Amplitude</th>\n",
       "      <th>Decomp0_Kurtosis Amplitude</th>\n",
       "      <th>Decomp1_Duration</th>\n",
       "      <th>Decomp1_Energy</th>\n",
       "      <th>Decomp1_Peak Amplitude</th>\n",
       "      <th>...</th>\n",
       "      <th>Decomp3_Std Amplitude</th>\n",
       "      <th>Decomp3_Skew Amplitude</th>\n",
       "      <th>Decomp3_Kurtosis Amplitude</th>\n",
       "      <th>Decomp4_Duration</th>\n",
       "      <th>Decomp4_Energy</th>\n",
       "      <th>Decomp4_Peak Amplitude</th>\n",
       "      <th>Decomp4_Mean Amplitude</th>\n",
       "      <th>Decomp4_Std Amplitude</th>\n",
       "      <th>Decomp4_Skew Amplitude</th>\n",
       "      <th>Decomp4_Kurtosis Amplitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.495519</td>\n",
       "      <td>1.988746</td>\n",
       "      <td>1.520042</td>\n",
       "      <td>1.587052</td>\n",
       "      <td>3.519293</td>\n",
       "      <td>-0.836662</td>\n",
       "      <td>-0.382522</td>\n",
       "      <td>-0.495519</td>\n",
       "      <td>1.101405</td>\n",
       "      <td>5.037063</td>\n",
       "      <td>...</td>\n",
       "      <td>3.630133</td>\n",
       "      <td>-0.799979</td>\n",
       "      <td>-0.649064</td>\n",
       "      <td>-0.495516</td>\n",
       "      <td>1.335286</td>\n",
       "      <td>3.177899</td>\n",
       "      <td>1.027847</td>\n",
       "      <td>3.666648</td>\n",
       "      <td>0.043408</td>\n",
       "      <td>0.001250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.148776</td>\n",
       "      <td>-0.484407</td>\n",
       "      <td>-1.967521</td>\n",
       "      <td>-0.957998</td>\n",
       "      <td>-1.510138</td>\n",
       "      <td>-0.440362</td>\n",
       "      <td>1.037689</td>\n",
       "      <td>-0.148776</td>\n",
       "      <td>-0.108832</td>\n",
       "      <td>-0.505122</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.645917</td>\n",
       "      <td>-0.801656</td>\n",
       "      <td>-0.654480</td>\n",
       "      <td>-0.148758</td>\n",
       "      <td>-0.165190</td>\n",
       "      <td>-0.494659</td>\n",
       "      <td>-0.332482</td>\n",
       "      <td>-0.549334</td>\n",
       "      <td>-0.825223</td>\n",
       "      <td>-0.749078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.083047</td>\n",
       "      <td>-0.099754</td>\n",
       "      <td>0.263997</td>\n",
       "      <td>-0.350288</td>\n",
       "      <td>-0.183049</td>\n",
       "      <td>-0.852198</td>\n",
       "      <td>-0.117095</td>\n",
       "      <td>1.083047</td>\n",
       "      <td>-0.105456</td>\n",
       "      <td>-0.318330</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.340923</td>\n",
       "      <td>0.944944</td>\n",
       "      <td>1.567820</td>\n",
       "      <td>1.083066</td>\n",
       "      <td>-0.157835</td>\n",
       "      <td>-0.205753</td>\n",
       "      <td>-0.332719</td>\n",
       "      <td>-0.384611</td>\n",
       "      <td>1.516972</td>\n",
       "      <td>1.394032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.060607</td>\n",
       "      <td>-0.479304</td>\n",
       "      <td>-1.537421</td>\n",
       "      <td>-0.914547</td>\n",
       "      <td>-1.417831</td>\n",
       "      <td>-0.508506</td>\n",
       "      <td>1.511734</td>\n",
       "      <td>1.060607</td>\n",
       "      <td>0.069316</td>\n",
       "      <td>6.960647</td>\n",
       "      <td>...</td>\n",
       "      <td>0.762387</td>\n",
       "      <td>-0.801451</td>\n",
       "      <td>-0.479740</td>\n",
       "      <td>1.060582</td>\n",
       "      <td>-0.049528</td>\n",
       "      <td>-0.243619</td>\n",
       "      <td>-0.217973</td>\n",
       "      <td>0.217508</td>\n",
       "      <td>-0.825181</td>\n",
       "      <td>-0.686848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.148776</td>\n",
       "      <td>-0.467346</td>\n",
       "      <td>-1.892627</td>\n",
       "      <td>-0.774353</td>\n",
       "      <td>-1.239665</td>\n",
       "      <td>-0.836177</td>\n",
       "      <td>-0.382370</td>\n",
       "      <td>-0.148776</td>\n",
       "      <td>-0.109003</td>\n",
       "      <td>-0.515888</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.648296</td>\n",
       "      <td>-0.798749</td>\n",
       "      <td>-0.603471</td>\n",
       "      <td>-0.148758</td>\n",
       "      <td>-0.165321</td>\n",
       "      <td>-0.480032</td>\n",
       "      <td>-0.361807</td>\n",
       "      <td>-0.551666</td>\n",
       "      <td>-0.740903</td>\n",
       "      <td>-0.721545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Decomp0_Duration  Decomp0_Energy  Decomp0_Peak Amplitude  \\\n",
       "0         -0.495519        1.988746                1.520042   \n",
       "1         -0.148776       -0.484407               -1.967521   \n",
       "2          1.083047       -0.099754                0.263997   \n",
       "3          1.060607       -0.479304               -1.537421   \n",
       "4         -0.148776       -0.467346               -1.892627   \n",
       "\n",
       "   Decomp0_Mean Amplitude  Decomp0_Std Amplitude  Decomp0_Skew Amplitude  \\\n",
       "0                1.587052               3.519293               -0.836662   \n",
       "1               -0.957998              -1.510138               -0.440362   \n",
       "2               -0.350288              -0.183049               -0.852198   \n",
       "3               -0.914547              -1.417831               -0.508506   \n",
       "4               -0.774353              -1.239665               -0.836177   \n",
       "\n",
       "   Decomp0_Kurtosis Amplitude  Decomp1_Duration  Decomp1_Energy  \\\n",
       "0                   -0.382522         -0.495519        1.101405   \n",
       "1                    1.037689         -0.148776       -0.108832   \n",
       "2                   -0.117095          1.083047       -0.105456   \n",
       "3                    1.511734          1.060607        0.069316   \n",
       "4                   -0.382370         -0.148776       -0.109003   \n",
       "\n",
       "   Decomp1_Peak Amplitude  ...  Decomp3_Std Amplitude  Decomp3_Skew Amplitude  \\\n",
       "0                5.037063  ...               3.630133               -0.799979   \n",
       "1               -0.505122  ...              -0.645917               -0.801656   \n",
       "2               -0.318330  ...              -0.340923                0.944944   \n",
       "3                6.960647  ...               0.762387               -0.801451   \n",
       "4               -0.515888  ...              -0.648296               -0.798749   \n",
       "\n",
       "   Decomp3_Kurtosis Amplitude  Decomp4_Duration  Decomp4_Energy  \\\n",
       "0                   -0.649064         -0.495516        1.335286   \n",
       "1                   -0.654480         -0.148758       -0.165190   \n",
       "2                    1.567820          1.083066       -0.157835   \n",
       "3                   -0.479740          1.060582       -0.049528   \n",
       "4                   -0.603471         -0.148758       -0.165321   \n",
       "\n",
       "   Decomp4_Peak Amplitude  Decomp4_Mean Amplitude  Decomp4_Std Amplitude  \\\n",
       "0                3.177899                1.027847               3.666648   \n",
       "1               -0.494659               -0.332482              -0.549334   \n",
       "2               -0.205753               -0.332719              -0.384611   \n",
       "3               -0.243619               -0.217973               0.217508   \n",
       "4               -0.480032               -0.361807              -0.551666   \n",
       "\n",
       "   Decomp4_Skew Amplitude  Decomp4_Kurtosis Amplitude  \n",
       "0                0.043408                    0.001250  \n",
       "1               -0.825223                   -0.749078  \n",
       "2                1.516972                    1.394032  \n",
       "3               -0.825181                   -0.686848  \n",
       "4               -0.740903                   -0.721545  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = audio_data.drop('label', axis=1)\n",
    "y = audio_data['label']\n",
    "\n",
    "# Initialize the scaler object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Normalize the data\n",
    "X_normalized = scaler.fit_transform(X)\n",
    "\n",
    "# Convert the numpy array back to a Pandas dataframe (if needed)\n",
    "X = pd.DataFrame(X_normalized, columns=X.columns)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa3a6c8",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "4117a86b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6647401247401248\n",
      "Precision:  0.62366713022258\n",
      "Recall:  0.3587070471753057\n",
      "F1-score:  0.4546453676568353\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "#Spliting the data stored in training-a\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the logistic regression model\n",
    "logistic_regression = LogisticRegression(max_iter=1000, C=1.5601864044243652)\n",
    "\n",
    "# Perform cross-validation\n",
    "scoring = ['accuracy', 'precision', 'recall', 'f1']\n",
    "cv_results = cross_validate(logistic_regression, X_train, y_train, cv=10, scoring=scoring)\n",
    "\n",
    "# Compute the performance metrics\n",
    "accuracy = cv_results['test_accuracy'].mean()\n",
    "precision = cv_results['test_precision'].mean()\n",
    "recall = cv_results['test_recall'].mean()\n",
    "f1 = cv_results['test_f1'].mean()\n",
    "\n",
    "# Print the performance metrics\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F1-score: \", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5711e2",
   "metadata": {},
   "source": [
    "# KNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "01f8df8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6172839506172839\n",
      "Recall:  0.6172839506172839\n",
      "Precision:  0.6125285779606767\n",
      "F1-score:  0.6139126078672209\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Perform cross-validation\n",
    "scoring = ['accuracy', 'precision', 'recall', 'f1']\n",
    "cv_results = cross_validate(knn, X_train, y_train, cv=10, scoring=scoring)\n",
    "\n",
    "# Create a KNN classifier object\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Use the trained classifier to make predictions on the testing data\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the classifier\n",
    "#What is the ratio of correct predictions for this model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "# When the model signals an at-risk heartbeat, how often is it correct?\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "#What percentage of at-risk heartbeats is the model able to flag\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "#What is the model's ability to flag as many at-risk heartbeats as possible while limiting false alarms\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"F1-score: \", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f847a9ac",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b0541a",
   "metadata": {},
   "source": [
    "## Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "5191798f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6435185185185185\n",
      "Precision: 0.6413895993179881\n",
      "Recall: 0.597605712548185\n",
      "F1 score: 0.5862949563736966\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize SVM classifier\n",
    "SVC = SVC(kernel='linear', C = 10)\n",
    "\n",
    "# Perform cross-validation\n",
    "scoring = ['accuracy', 'precision', 'recall', 'f1']\n",
    "cv_results = cross_validate(SVC, X_train, y_train, cv=10, scoring=scoring)\n",
    "\n",
    "# Fit classifier to training data\n",
    "SVC.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on test data\n",
    "y_pred = SVC.predict(X_test)\n",
    "\n",
    "# Evaluate model performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "# Print evaluation metrics\n",
    "print('Accuracy:', accuracy)\n",
    "print('Precision:', precision)\n",
    "print('Recall:', recall)\n",
    "print('F1 score:', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49559cd",
   "metadata": {},
   "source": [
    "## Kernel SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "309573d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6574074074074074\n",
      "Precision: 0.6452147508206187\n",
      "Recall: 0.6332159566850741\n",
      "F1 score: 0.634567901234568\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize SVM classifier\n",
    "SVC = SVC(kernel='rbf', C = 10)\n",
    "\n",
    "# Perform cross-validation\n",
    "scoring = ['accuracy', 'precision', 'recall', 'f1']\n",
    "cv_results = cross_validate(SVC, X_train, y_train, cv=10, scoring=scoring)\n",
    "\n",
    "# Fit classifier to training data\n",
    "SVC.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on test data\n",
    "y_pred = SVC.predict(X_test)\n",
    "\n",
    "# Evaluate model performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "# Print evaluation metrics\n",
    "print('Accuracy:', accuracy)\n",
    "print('Precision:', precision)\n",
    "print('Recall:', recall)\n",
    "print('F1 score:', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16351df",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "cdc97ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6342592592592593\n",
      "Precision:  0.6272147093992888\n",
      "Recall:  0.6342592592592593\n",
      "F1-score:  0.6270384786379799\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Perform cross-validation\n",
    "scoring = ['accuracy', 'precision', 'recall', 'f1']\n",
    "cv_results = cross_validate(SVC, X_train, y_train, cv=10, scoring=scoring)\n",
    "\n",
    "# Initialize the decision tree classifier\n",
    "decision_tree = DecisionTreeClassifier(max_depth=2)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "decision_tree.fit(X_train, y_train)\n",
    "\n",
    "# Use the trained classifier to make predictions on the testing data\n",
    "y_pred = decision_tree.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Print the performance metrics\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F1-score: \", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1c6b78",
   "metadata": {},
   "source": [
    "# Confusrion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b31afe34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression confusion matrix:\n",
      "[[314  65]\n",
      " [177  92]]\n",
      "\n",
      "KNN confusion matrix:\n",
      "[[268 111]\n",
      " [137 132]]\n",
      "\n",
      "SVM with linear kernel confusion matrix:\n",
      "[[341  38]\n",
      " [210  59]]\n",
      "\n",
      "SVM with RBF kernel confusion matrix:\n",
      "[[333  46]\n",
      " [196  73]]\n",
      "\n",
      "Decision Tree confusion matrix:\n",
      "[[285  94]\n",
      " [143 126]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Initialize the models\n",
    "logistic_regression = LogisticRegression(max_iter=1000, C=1.5601864044243652)\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "svm_linear = SVC(kernel='linear', C=0.01)\n",
    "svm_rbf = SVC(kernel='rbf', C=10, gamma=0.001)\n",
    "\n",
    "# Train the models on the training data\n",
    "logistic_regression.fit(X_train, y_train)\n",
    "knn.fit(X_train, y_train)\n",
    "svm_linear.fit(X_train, y_train)\n",
    "svm_rbf.fit(X_train, y_train)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "\n",
    "# Use the trained models to make predictions on the testing data\n",
    "y_pred_lr = logistic_regression.predict(X_test)\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "y_pred_svm_linear = svm_linear.predict(X_test)\n",
    "y_pred_svm_rbf = svm_rbf.predict(X_test)\n",
    "y_pred_svm_dec_tree = decision_tree.predict(X_test)\n",
    "\n",
    "# Compute the confusion matrices\n",
    "cm_lr = confusion_matrix(y_test, y_pred_lr)\n",
    "cm_knn = confusion_matrix(y_test, y_pred_knn)\n",
    "cm_svm_linear = confusion_matrix(y_test, y_pred_svm_linear)\n",
    "cm_svm_rbf = confusion_matrix(y_test, y_pred_svm_rbf)\n",
    "cm_svm_dec_tree = confusion_matrix(y_test, y_pred_svm_dec_tree)\n",
    "\n",
    "# Print the confusion matrices\n",
    "print(\"Logistic Regression confusion matrix:\")\n",
    "print(cm_lr)\n",
    "print(\"\\nKNN confusion matrix:\")\n",
    "print(cm_knn)\n",
    "print(\"\\nSVM with linear kernel confusion matrix:\")\n",
    "print(cm_svm_linear)\n",
    "print(\"\\nSVM with RBF kernel confusion matrix:\")\n",
    "print(cm_svm_rbf)\n",
    "print(\"\\nDecision Tree confusion matrix:\")\n",
    "print(cm_svm_dec_tree)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
